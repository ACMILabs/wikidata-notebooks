{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338757\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>creatorLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q261</td>\n",
       "      <td>Linkin Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q272</td>\n",
       "      <td>Paul Morand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1225</td>\n",
       "      <td>Bruce Springsteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wikidata.org/entity/Q11319</td>\n",
       "      <td>David DeCoteau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wikidata.org/entity/Q181</td>\n",
       "      <td>Jimmy Wales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 creator       creatorLabel\n",
       "0    http://www.wikidata.org/entity/Q261        Linkin Park\n",
       "1    http://www.wikidata.org/entity/Q272        Paul Morand\n",
       "2   http://www.wikidata.org/entity/Q1225  Bruce Springsteen\n",
       "3  http://www.wikidata.org/entity/Q11319     David DeCoteau\n",
       "4    http://www.wikidata.org/entity/Q181        Jimmy Wales"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of wikidata creators\n",
    "# then using acmi creator list find instance in which there are no reasonable matches\n",
    "\n",
    "from rapidfuzz import process, fuzz\n",
    "import hashlib\n",
    "import numpy\n",
    "import pandas\n",
    "import pathlib\n",
    "import pydash\n",
    "import requests\n",
    "import time\n",
    "import tqdm\n",
    "import unidecode\n",
    "\n",
    "def value_extract(row, column):\n",
    "\n",
    "    ''' Extract dictionary values. '''\n",
    "    \n",
    "    return pydash.get(row[column], 'value')\n",
    "\n",
    "def sparql_query(query, service):\n",
    "\n",
    "    ''' Send sparql request, and formulate results into a dataframe. '''\n",
    "\n",
    "    response = requests.get(service, params={'format': 'json', 'query': query}, timeout=120)\n",
    "    results = pydash.get(response.json(), 'results.bindings')\n",
    "    df = pandas.DataFrame.from_dict(results)\n",
    "    for column in df.columns:\n",
    "        df[column] = df.apply(value_extract, column=column, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def normalise_string(input_text):\n",
    "\n",
    "    ''' Normalise text for matching purposes. '''\n",
    "\n",
    "    return unidecode.unidecode(str(input_text).lower()).strip()\n",
    "\n",
    "wikidata_creator_data = pathlib.Path.cwd().parents[0] / 'data' / 'creator_match' / 'wikidata_creator.parquet'\n",
    "if not wikidata_creator_data.exists():\n",
    "    query = '''\n",
    "    select distinct ?creator \n",
    "        where {\n",
    "            {?work wdt:P57 ?creator . } union\n",
    "            {?work wdt:P58 ?creator . } union\n",
    "            {?work wdt:P161 ?creator . } union\n",
    "            {?work wdt:P272 ?creator . } union\n",
    "            {?work wdt:P344 ?creator . } union\n",
    "            {?work wdt:P1040 ?creator . } union\n",
    "            {?work wdt:P2515 ?creator . } union\n",
    "            {?work wdt:P2554 ?creator . } \n",
    "        } '''\n",
    "\n",
    "    wikidata_creators = sparql_query(query, 'https://query.wikidata.org/sparql').drop_duplicates()\n",
    "    wikidata_creators['creator'] = wikidata_creators['creator'].str.split('/').str[-1]\n",
    "\n",
    "    wikidata_dataframe = pandas.DataFrame()\n",
    "    for chunk in tqdm.tqdm(numpy.array_split(wikidata_creators.creator.unique(), 2000)):\n",
    "        time.sleep(4)\n",
    "        query = '''\n",
    "            select distinct ?creator ?creatorLabel\n",
    "            where {\n",
    "                values ?creator {'''+' '.join([f'wd:{x}' for x in chunk])+'''}\n",
    "                service wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" }\n",
    "            } '''\n",
    "        wikidata_dataframe = pandas.concat([wikidata_dataframe, sparql_query(query, 'https://query.wikidata.org/sparql')])\n",
    "    wikidata_dataframe.to_parquet(wikidata_creator_data)\n",
    "else:\n",
    "    wikidata_dataframe = pandas.read_parquet(wikidata_creator_data)\n",
    "\n",
    "wikidata_dataframe['creatorLabel'] = wikidata_dataframe['creatorLabel'].str.lower()\n",
    "\n",
    "print(len(wikidata_dataframe))\n",
    "wikidata_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52400147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm1588970</td>\n",
       "      <td>Carmencita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0005690</td>\n",
       "      <td>Carmencita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0374658</td>\n",
       "      <td>Carmencita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0721526</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm1335271</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nconst                   title\n",
       "0  nm1588970              Carmencita\n",
       "1  nm0005690              Carmencita\n",
       "2  nm0374658              Carmencita\n",
       "3  nm0721526  Le clown et ses chiens\n",
       "4  nm1335271  Le clown et ses chiens"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imdb dataframe\n",
    "\n",
    "# what do you need to know, nameconst, connected to names of films, try jacki weaver\n",
    "\n",
    "\n",
    "imdb_data_path = pathlib.Path.cwd().parents[0] / 'data' / 'creator_match' / 'imdb_data.parquet'\n",
    "if not imdb_data_path.exists():\n",
    "    imdb_data = pandas.read_csv(pathlib.Path.home() / 'imdb' / 'title.principals.tsv', delimiter='\\t', low_memory=False)\n",
    "    imdb_data = pandas.merge(imdb_data, pandas.read_csv(pathlib.Path.home() / 'imdb' / 'title.basics.tsv', delimiter='\\t', low_memory=False), on='tconst', how='left')\n",
    "    imdb_data = pandas.concat([\n",
    "        imdb_data[['nconst', 'primaryTitle']].rename(columns={'primaryTitle':'title'}),\n",
    "        imdb_data[['nconst', 'originalTitle']].rename(columns={'originalTitle':'title'})]).drop_duplicates()\n",
    "    imdb_data.to_parquet(imdb_data_path, index=False)\n",
    "else:\n",
    "    imdb_data = pandas.read_parquet(imdb_data_path)\n",
    "    \n",
    "print(len(imdb_data))\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>creator_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>works/119934</td>\n",
       "      <td>The Dame Was Loaded German advertisement</td>\n",
       "      <td>creators/41813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>works/115143</td>\n",
       "      <td>World Is Ours</td>\n",
       "      <td>creators/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>works/90799</td>\n",
       "      <td>Wing Chun</td>\n",
       "      <td>creators/32508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works/90495</td>\n",
       "      <td>The Flying doctor</td>\n",
       "      <td>creators/11967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works/90495</td>\n",
       "      <td>The Flying doctor</td>\n",
       "      <td>creators/12786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                     title      creator_id\n",
       "0  works/119934  The Dame Was Loaded German advertisement  creators/41813\n",
       "1  works/115143                             World Is Ours       creators/\n",
       "2   works/90799                                 Wing Chun  creators/32508\n",
       "3   works/90495                         The Flying doctor  creators/11967\n",
       "3   works/90495                         The Flying doctor  creators/12786"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acmi_works = pandas.read_csv(pathlib.Path.cwd().parents[0] / 'acmi-api' / 'app' / 'tsv' / 'works.tsv', delimiter='\\t', low_memory=False)\n",
    "acmi_works = pandas.concat([\n",
    "    acmi_works[['id', 'title', 'creators_primary']].rename(columns={'creators_primary':'creator_id'}),\n",
    "    acmi_works[['id', 'title', 'creators_other']].rename(columns={'creators_other':'creator_id'})\n",
    "])\n",
    "\n",
    "acmi_works['creator_id'] = acmi_works['creator_id'].str.split(',')\n",
    "acmi_works = acmi_works.explode('creator_id')\n",
    "acmi_works['creator_id'] = acmi_works['creator_id'].str.strip()\n",
    "acmi_works = acmi_works.drop_duplicates().fillna('')\n",
    "acmi_works['id'] = 'works/'+acmi_works['id'].astype(str)\n",
    "acmi_works['creator_id'] = 'creators/'+acmi_works['creator_id'].astype(str)\n",
    "\n",
    "print(len(acmi_works))\n",
    "acmi_works.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1369.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "query = '''\n",
    "    select ?acmi_id ?wikidata_id\n",
    "    where {\n",
    "        ?wikidata_id wdt:P7003 ?acmi_id .\n",
    "        filter(regex(str(?acmi_id), \"creators\")) .\n",
    "        } '''\n",
    "\n",
    "extant_links = sparql_query(query, 'https://query.wikidata.org/sparql').drop_duplicates()\n",
    "acmi_creators = pandas.read_csv(pathlib.Path.cwd().parents[0] / 'acmi-api' / 'app' / 'tsv' / 'creators.tsv', delimiter='\\t', low_memory=False)\n",
    "acmi_creators = acmi_creators[['id', 'name']].rename(columns={'id':'acmi_id', 'name':'acmi_label'})\n",
    "acmi_creators['acmi_id'] = 'creators/'+acmi_creators['acmi_id'].astype(str)\n",
    "acmi_creators = acmi_creators.loc[~acmi_creators.acmi_id.isin(list(extant_links.acmi_id))]\n",
    "\n",
    "# ideal here is to add increasing checks\n",
    "\n",
    "def wikidata_titles(wikidata):\n",
    "\n",
    "    query = '''\n",
    "    select distinct ?workLabel \n",
    "    where {\n",
    "        values ?creator {wd:'''+wikidata+'''}\n",
    "        {?work wdt:P57 ?creator . } union\n",
    "        {?work wdt:P58 ?creator . } union\n",
    "        {?work wdt:P161 ?creator . } union\n",
    "        {?work wdt:P272 ?creator . } union\n",
    "        {?work wdt:P344 ?creator . } union\n",
    "        {?work wdt:P1040 ?creator . } union\n",
    "        {?work wdt:P2515 ?creator . } union\n",
    "        {?work wdt:P2554 ?creator . } \n",
    "        service wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" }\n",
    "    } '''\n",
    "\n",
    "    titles = sparql_query(query, 'https://query.wikidata.org/sparql')\n",
    "    if len(titles):\n",
    "        return titles.workLabel.unique()\n",
    "\n",
    "def wikipedia_page(wikidata):\n",
    "\n",
    "    query = '''\n",
    "    select distinct ?article\n",
    "    where { \n",
    "        values ?creator {wd:'''+wikidata+'''} .\n",
    "        ?article schema:about ?creator .\n",
    "        ?article schema:isPartOf <https://en.wikipedia.org/>  .\n",
    "    } '''\n",
    "    \n",
    "    titles = sparql_query(query, 'https://query.wikidata.org/sparql')\n",
    "    if len(titles):\n",
    "        return titles.article.unique()\n",
    "\n",
    "def imdb_page(wikidata):\n",
    "    \n",
    "    query = '''\n",
    "    select distinct ?imdb\n",
    "    where { \n",
    "        values ?creator {wd:'''+wikidata+'''} .\n",
    "        ?creator wdt:P345 ?imdb .\n",
    "    } '''\n",
    "    \n",
    "    titles = sparql_query(query, 'https://query.wikidata.org/sparql')\n",
    "    if len(titles):\n",
    "        return titles.imdb.unique()\n",
    "\n",
    "\n",
    "creator_result = pandas.DataFrame(columns=['acmi', 'wikidata'])\n",
    "\n",
    "for creator in tqdm.tqdm(acmi_creators.to_dict('records')[:500]):\n",
    "    \n",
    "    hash_id = hashlib.md5(creator['acmi_id'].encode()).hexdigest()\n",
    "    hash_path = pathlib.Path.cwd().parents[0] / 'data' / 'creator_match' / f'{hash_id}.txt'\n",
    "\n",
    "\n",
    "    if not hash_path.exists():\n",
    "\n",
    "        c = process.extract(creator['acmi_label'], wikidata_dataframe.creatorLabel.unique(), scorer=fuzz.WRatio, limit=40)\n",
    "        candidates = [x[0] for x in c if x[1] > 75] # this should be 60\n",
    "\n",
    "        match = ''\n",
    "\n",
    "        if len(candidates):\n",
    "\n",
    "            acmi_filmography = acmi_works.copy()\n",
    "            acmi_filmography = acmi_filmography.loc[acmi_filmography.creator_id.isin([creator['acmi_id']])]\n",
    "            acmi_filmography = [x['title'] for x in acmi_filmography.to_dict('records')]\n",
    "\n",
    "            candidate_dataframe = wikidata_dataframe.copy()\n",
    "            candidate_dataframe = candidate_dataframe.loc[candidate_dataframe.creatorLabel.isin(candidates)]\n",
    "\n",
    "            for wikidata_candidate in candidate_dataframe.creator.unique():\n",
    "\n",
    "                wikidata_id = wikidata_candidate.split('/')[-1]\n",
    "                wikidata_titles_array = wikidata_titles(wikidata_id)\n",
    "                film_results = [process.extractOne(f[1], wikidata_titles_array, scorer=fuzz.WRatio)[1] for f in acmi_filmography]\n",
    "                wikipedia_page_result = wikipedia_page(wikidata_id)\n",
    "                if wikipedia_page_result:\n",
    "                    if len(wikipedia_page_result) == 1:\n",
    "                        time.sleep(2)\n",
    "                        r = requests.get(wikipedia_page_result[0]).text  \n",
    "                        for g in acmi_filmography:\n",
    "                            if g in r:\n",
    "                                match = wikidata_candidate\n",
    "        \n",
    "                imdb_page_result = imdb_page(wikidata_id)\n",
    "                if imdb_page_result:\n",
    "                    if len(imdb_page_result) == 1:\n",
    "                        imdb_data_candidate = imdb_data.loc[imdb_data.nconst.isin([imdb_page_result[0]])]\n",
    "                        for g in acmi_filmography:\n",
    "                            if g in imdb_data_candidate.title.unique():\n",
    "                                match = wikidata_candidate\n",
    "\n",
    "        with open(hash_path, 'w') as export:\n",
    "            export.write(f\"{creator['acmi_id']} {match}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
