{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulduchesne/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338842\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>creatorLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q261</td>\n",
       "      <td>LINKIN PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q272</td>\n",
       "      <td>PAUL MORAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1225</td>\n",
       "      <td>BRUCE SPRINGSTEEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wikidata.org/entity/Q11319</td>\n",
       "      <td>DAVID DECOTEAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wikidata.org/entity/Q181</td>\n",
       "      <td>JIMMY WALES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 creator       creatorLabel\n",
       "0    http://www.wikidata.org/entity/Q261        LINKIN PARK\n",
       "1    http://www.wikidata.org/entity/Q272        PAUL MORAND\n",
       "2   http://www.wikidata.org/entity/Q1225  BRUCE SPRINGSTEEN\n",
       "3  http://www.wikidata.org/entity/Q11319     DAVID DECOTEAU\n",
       "4    http://www.wikidata.org/entity/Q181        JIMMY WALES"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of wikidata creators\n",
    "# then using acmi creator list find instance in which there are no reasonable matches\n",
    "\n",
    "from rapidfuzz import process, fuzz\n",
    "import hashlib\n",
    "import numpy\n",
    "import pandas\n",
    "import pathlib\n",
    "import pydash\n",
    "import requests\n",
    "import time\n",
    "import tqdm\n",
    "import unidecode\n",
    "\n",
    "def value_extract(row, column):\n",
    "\n",
    "    ''' Extract dictionary values. '''\n",
    "    \n",
    "    return pydash.get(row[column], 'value')\n",
    "\n",
    "def sparql_query(query, service):\n",
    "\n",
    "    ''' Send sparql request, and formulate results into a dataframe. '''\n",
    "\n",
    "    response = requests.get(service, params={'format': 'json', 'query': query}, timeout=120)\n",
    "    results = pydash.get(response.json(), 'results.bindings')\n",
    "    df = pandas.DataFrame.from_dict(results)\n",
    "    for column in df.columns:\n",
    "        df[column] = df.apply(value_extract, column=column, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def normalise_string(input_text):\n",
    "\n",
    "    ''' Normalise text for matching purposes. '''\n",
    "\n",
    "    return unidecode.unidecode(str(input_text).lower()).strip()\n",
    "\n",
    "wikidata_creator_data = pathlib.Path.cwd().parents[0] / 'data' / 'creator_match' / 'wikidata_creator.parquet'\n",
    "if not wikidata_creator_data.exists():\n",
    "    query = '''\n",
    "    select distinct ?creator \n",
    "        where {\n",
    "            {?work wdt:P57 ?creator . } union\n",
    "            {?work wdt:P58 ?creator . } union\n",
    "            {?work wdt:P161 ?creator . } union\n",
    "            {?work wdt:P272 ?creator . } union\n",
    "            {?work wdt:P344 ?creator . } union\n",
    "            {?work wdt:P1040 ?creator . } union\n",
    "            {?work wdt:P2515 ?creator . } union\n",
    "            {?work wdt:P2554 ?creator . } \n",
    "        } '''\n",
    "\n",
    "    wikidata_creators = sparql_query(query, 'https://query.wikidata.org/sparql').drop_duplicates()\n",
    "    wikidata_creators['creator'] = wikidata_creators['creator'].str.split('/').str[-1]\n",
    "\n",
    "    wikidata_dataframe = pandas.DataFrame()\n",
    "    for chunk in tqdm.tqdm(numpy.array_split(wikidata_creators.creator.unique(), 2000)):\n",
    "        time.sleep(4)\n",
    "        query = '''\n",
    "            select distinct ?creator ?creatorLabel\n",
    "            where {\n",
    "                values ?creator {'''+' '.join([f'wd:{x}' for x in chunk])+'''}\n",
    "                service wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" }\n",
    "            } '''\n",
    "        wikidata_dataframe = pandas.concat([wikidata_dataframe, sparql_query(query, 'https://query.wikidata.org/sparql')])\n",
    "    wikidata_dataframe.to_parquet(wikidata_creator_data)\n",
    "else:\n",
    "    wikidata_dataframe = pandas.read_parquet(wikidata_creator_data)\n",
    "\n",
    "wikidata_dataframe['creatorLabel'] = wikidata_dataframe['creatorLabel'].str.upper()\n",
    "\n",
    "print(len(wikidata_dataframe))\n",
    "wikidata_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52400147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm1588970</td>\n",
       "      <td>CARMENCITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0005690</td>\n",
       "      <td>CARMENCITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0374658</td>\n",
       "      <td>CARMENCITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0721526</td>\n",
       "      <td>LE CLOWN ET SES CHIENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm1335271</td>\n",
       "      <td>LE CLOWN ET SES CHIENS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nconst                   title\n",
       "0  nm1588970              CARMENCITA\n",
       "1  nm0005690              CARMENCITA\n",
       "2  nm0374658              CARMENCITA\n",
       "3  nm0721526  LE CLOWN ET SES CHIENS\n",
       "4  nm1335271  LE CLOWN ET SES CHIENS"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imdb dataframe\n",
    "\n",
    "imdb_data_path = pathlib.Path.cwd().parents[0] / 'data' / 'creator_match' / 'imdb_data.parquet'\n",
    "if not imdb_data_path.exists():\n",
    "    imdb_data = pandas.read_csv(pathlib.Path.home() / 'imdb' / 'title.principals.tsv', delimiter='\\t', low_memory=False)\n",
    "    imdb_data = pandas.merge(imdb_data, pandas.read_csv(pathlib.Path.home() / 'imdb' / 'title.basics.tsv', delimiter='\\t', low_memory=False), on='tconst', how='left')\n",
    "    imdb_data = pandas.concat([\n",
    "        imdb_data[['nconst', 'primaryTitle']].rename(columns={'primaryTitle':'title'}),\n",
    "        imdb_data[['nconst', 'originalTitle']].rename(columns={'originalTitle':'title'})]).drop_duplicates()\n",
    "    imdb_data.to_parquet(imdb_data_path, index=False)\n",
    "else:\n",
    "    imdb_data = pandas.read_parquet(imdb_data_path)\n",
    "    \n",
    "imdb_data['title'] = imdb_data['title'].str.upper()\n",
    "\n",
    "print(len(imdb_data))\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122473\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>creator_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>works/119934</td>\n",
       "      <td>THE DAME WAS LOADED GERMAN ADVERTISEMENT</td>\n",
       "      <td>creators/41813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>works/90799</td>\n",
       "      <td>WING CHUN</td>\n",
       "      <td>creators/32508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works/90495</td>\n",
       "      <td>THE FLYING DOCTOR</td>\n",
       "      <td>creators/11967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works/90495</td>\n",
       "      <td>THE FLYING DOCTOR</td>\n",
       "      <td>creators/12786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works/90495</td>\n",
       "      <td>THE FLYING DOCTOR</td>\n",
       "      <td>creators/32223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                     title      creator_id\n",
       "0  works/119934  THE DAME WAS LOADED GERMAN ADVERTISEMENT  creators/41813\n",
       "2   works/90799                                 WING CHUN  creators/32508\n",
       "3   works/90495                         THE FLYING DOCTOR  creators/11967\n",
       "3   works/90495                         THE FLYING DOCTOR  creators/12786\n",
       "3   works/90495                         THE FLYING DOCTOR  creators/32223"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acmi_works = pandas.read_csv(pathlib.Path.cwd().parents[0] / 'acmi-api' / 'app' / 'tsv' / 'works.tsv', delimiter='\\t', low_memory=False)\n",
    "acmi_works = pandas.concat([\n",
    "    acmi_works[['id', 'title', 'creators_primary']].rename(columns={'creators_primary':'creator_id'}),\n",
    "    acmi_works[['id', 'title', 'creators_other']].rename(columns={'creators_other':'creator_id'})\n",
    "])\n",
    "\n",
    "acmi_works['creator_id'] = acmi_works['creator_id'].str.split(',')\n",
    "acmi_works = acmi_works.explode('creator_id')\n",
    "acmi_works['creator_id'] = acmi_works['creator_id'].str.strip()\n",
    "acmi_works = acmi_works.drop_duplicates().fillna('')\n",
    "acmi_works = acmi_works.loc[~acmi_works.creator_id.isin([''])]\n",
    "\n",
    "acmi_works['id'] = 'works/'+acmi_works['id'].astype(str)\n",
    "acmi_works['creator_id'] = 'creators/'+acmi_works['creator_id'].astype(str)\n",
    "\n",
    "for x in ['[DVD]', '[Widescreen]', '[NTSC]', '[B&W]', '[Italian version]',\n",
    "    '[Edited version]', '[Greek version]', '[study extract]', '[Dubbed]',\n",
    "    '[Turkish version]', '[game trailer]', '[a discussion]']:\n",
    "    acmi_works['title'] = acmi_works['title'].str.replace(x, '')\n",
    "\n",
    "acmi_works['title'] = acmi_works['title'].str.split('=')\n",
    "acmi_works = acmi_works.explode('title')\n",
    "acmi_works['title'] = acmi_works['title'].str.strip()\n",
    "acmi_works['title'] = acmi_works['title'].str.upper()\n",
    "\n",
    "print(len(acmi_works))\n",
    "acmi_works.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2374/13658 [1:17:56<178:37:05, 56.99s/it]"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "query = '''\n",
    "    select ?acmi_id ?wikidata_id\n",
    "    where {\n",
    "        ?wikidata_id wdt:P7003 ?acmi_id .\n",
    "        filter(regex(str(?acmi_id), \"creators\")) .\n",
    "        } '''\n",
    "\n",
    "extant_links = sparql_query(query, 'https://query.wikidata.org/sparql').drop_duplicates()\n",
    "acmi_creators = pandas.read_csv(pathlib.Path.cwd().parents[0] / 'acmi-api' / 'app' / 'tsv' / 'creators.tsv', delimiter='\\t', low_memory=False)\n",
    "acmi_creators = acmi_creators[['id', 'name']].rename(columns={'id':'acmi_id', 'name':'acmi_label'})\n",
    "acmi_creators['acmi_id'] = 'creators/'+acmi_creators['acmi_id'].astype(str)\n",
    "acmi_creators = acmi_creators.loc[~acmi_creators.acmi_id.isin(list(extant_links.acmi_id))]\n",
    "acmi_creators['acmi_label'] = acmi_creators['acmi_label'].str.upper()\n",
    "\n",
    "# ideal here is to add increasing checks\n",
    "\n",
    "def wikidata_titles(wikidata):\n",
    "\n",
    "    query = '''\n",
    "    select distinct ?workLabel \n",
    "    where {\n",
    "        values ?creator {wd:'''+wikidata+'''}\n",
    "        {?work wdt:P57 ?creator . } union\n",
    "        {?work wdt:P58 ?creator . } union\n",
    "        {?work wdt:P161 ?creator . } union\n",
    "        {?work wdt:P272 ?creator . } union\n",
    "        {?work wdt:P344 ?creator . } union\n",
    "        {?work wdt:P1040 ?creator . } union\n",
    "        {?work wdt:P2515 ?creator . } union\n",
    "        {?work wdt:P2554 ?creator . } \n",
    "        service wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" }\n",
    "    } '''\n",
    "\n",
    "    titles = sparql_query(query, 'https://query.wikidata.org/sparql')\n",
    "    if len(titles):\n",
    "        return titles.workLabel.unique()\n",
    "\n",
    "def wikipedia_page(wikidata):\n",
    "\n",
    "    query = '''\n",
    "    select distinct ?article\n",
    "    where { \n",
    "        values ?creator {wd:'''+wikidata+'''} .\n",
    "        ?article schema:about ?creator .\n",
    "        ?article schema:isPartOf <https://en.wikipedia.org/>  .\n",
    "    } '''\n",
    "    \n",
    "    titles = sparql_query(query, 'https://query.wikidata.org/sparql')\n",
    "    if len(titles):\n",
    "        return titles.article.unique()\n",
    "\n",
    "def imdb_page(wikidata):\n",
    "    \n",
    "    query = '''\n",
    "    select distinct ?imdb\n",
    "    where { \n",
    "        values ?creator {wd:'''+wikidata+'''} .\n",
    "        ?creator wdt:P345 ?imdb .\n",
    "    } '''\n",
    "    \n",
    "    titles = sparql_query(query, 'https://query.wikidata.org/sparql')\n",
    "    if len(titles):\n",
    "        return titles.imdb.unique()\n",
    "\n",
    "\n",
    "for creator in tqdm.tqdm(acmi_creators.to_dict('records')):\n",
    "\n",
    "    #creator = {'acmi_id': 'creators/72103', 'acmi_label':'Steven Spielberg'}\n",
    "\n",
    "    hash_id = hashlib.md5(creator['acmi_id'].encode()).hexdigest()\n",
    "    hash_path = pathlib.Path.cwd().parents[0] / 'data' / 'creator_match' / f'{hash_id}.txt'\n",
    "\n",
    "    if not hash_path.exists():\n",
    "\n",
    "        acmi_filmography = acmi_works.copy()\n",
    "        acmi_filmography = acmi_filmography.loc[acmi_filmography.creator_id.isin([creator['acmi_id']])]\n",
    "        acmi_filmography = [x['title'] for x in acmi_filmography.to_dict('records')]\n",
    "\n",
    "        c = process.extract(creator['acmi_label'].upper(), wikidata_dataframe.creatorLabel.unique(), scorer=fuzz.WRatio, limit=10)\n",
    "        candidates = [x[0] for x in c if x[1] > 80] \n",
    "\n",
    "        match = ''\n",
    "\n",
    "        if len(candidates):\n",
    "\n",
    "            candidate_dataframe = wikidata_dataframe.copy()\n",
    "            candidate_dataframe = candidate_dataframe.loc[candidate_dataframe.creatorLabel.isin(candidates)]\n",
    "\n",
    "            for wikidata_candidate in candidate_dataframe.creator.unique():\n",
    "                wikidata_id = wikidata_candidate.split('/')[-1]\n",
    "\n",
    "                if match == '':\n",
    "                    wiki_titles = wikidata_titles(wikidata_id)\n",
    "                    if wiki_titles is not None:\n",
    "                        wikidata_titles_array = [a.upper() for a in wiki_titles]\n",
    "                        for g in acmi_filmography:\n",
    "                            if g in wikidata_titles_array:\n",
    "                                match = wikidata_candidate\n",
    "\n",
    "                if match == '':\n",
    "                    imdb_page_result = imdb_page(wikidata_id)\n",
    "                    if imdb_page_result is not None:\n",
    "                        if len(imdb_page_result) == 1:\n",
    "                            imdb_data_candidate = imdb_data.loc[imdb_data.nconst.isin([imdb_page_result[0]])]\n",
    "                            for g in acmi_filmography:\n",
    "                                if g in imdb_data_candidate.title.unique():\n",
    "                                    match = wikidata_candidate\n",
    " \n",
    "                if match == '':\n",
    "                    wikipedia_page_result = wikipedia_page(wikidata_id)\n",
    "                    if wikipedia_page_result:\n",
    "                        if len(wikipedia_page_result) == 1:\n",
    "                            r = requests.get(wikipedia_page_result[0])  \n",
    "                            if r.status_code == 200:\n",
    "                                for g in acmi_filmography:\n",
    "                                    if g in r.text.upper():\n",
    "                                        match = wikidata_candidate\n",
    "                            else:\n",
    "                                print('connection error')\n",
    "            \n",
    "\n",
    "        with open(hash_path, 'w') as export:\n",
    "            export.write(f\"{creator['acmi_id']} {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MediaWiki login warnings messages:\n",
      "* main: Subscribe to the mediawiki-api-announce mailing list at <https://lists.wikimedia.org/postorius/lists/mediawiki-api-announce.lists.wikimedia.org/> for notice of API deprecations and breaking changes. Use [[Special:ApiFeatureUsage]] to see usage of deprecated features by your application.\n",
      "* login: Main-account login via \"action=login\" is deprecated and may stop working without warning. To continue login with \"action=login\", see [[Special:BotPasswords]]. To safely continue using main-account login, see \"action=clientlogin\".\n",
      "100%|██████████| 266/266 [03:56<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acmi_link</th>\n",
       "      <th>acmi_id</th>\n",
       "      <th>acmi_creator_name</th>\n",
       "      <th>wikidata_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>creators/79205</td>\n",
       "      <td>79205</td>\n",
       "      <td>Allan Martel</td>\n",
       "      <td>Q5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>creators/80479</td>\n",
       "      <td>80479</td>\n",
       "      <td>Virginia Moncrieff</td>\n",
       "      <td>Q5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>creators/85174</td>\n",
       "      <td>85174</td>\n",
       "      <td>Gwen McCrorey</td>\n",
       "      <td>Q5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>creators/31546</td>\n",
       "      <td>31546</td>\n",
       "      <td>Heus-Stept Productions</td>\n",
       "      <td>Q11396960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>creators/78448</td>\n",
       "      <td>78448</td>\n",
       "      <td>Shaun Farrington</td>\n",
       "      <td>Q11396960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          acmi_link acmi_id       acmi_creator_name wikidata_type\n",
       "122  creators/79205   79205            Allan Martel            Q5\n",
       "123  creators/80479   80479      Virginia Moncrieff            Q5\n",
       "169  creators/85174   85174           Gwen McCrorey            Q5\n",
       "328  creators/31546   31546  Heus-Stept Productions     Q11396960\n",
       "331  creators/78448   78448        Shaun Farrington     Q11396960"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from rapidfuzz import process, fuzz\n",
    "import hashlib\n",
    "import numpy\n",
    "import pandas\n",
    "import pathlib\n",
    "import pydash\n",
    "import requests\n",
    "import time\n",
    "import tqdm\n",
    "import unidecode\n",
    "from wikibaseintegrator import WikibaseIntegrator, wbi_login, datatypes\n",
    "from wikibaseintegrator.models import Claims, Qualifiers, References, Reference\n",
    "from wikibaseintegrator.wbi_config import config\n",
    "from wikibaseintegrator.wbi_enums import ActionIfExists\n",
    "import json\n",
    "\n",
    "\n",
    "def value_extract(row, column):\n",
    "\n",
    "    ''' Extract dictionary values. '''\n",
    "    \n",
    "    return pydash.get(row[column], 'value')\n",
    "\n",
    "def sparql_query(query, service):\n",
    "\n",
    "    ''' Send sparql request, and formulate results into a dataframe. '''\n",
    "\n",
    "    response = requests.get(service, params={'format': 'json', 'query': query}, timeout=120)\n",
    "    results = pydash.get(response.json(), 'results.bindings')\n",
    "    df = pandas.DataFrame.from_dict(results)\n",
    "    for column in df.columns:\n",
    "        df[column] = df.apply(value_extract, column=column, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "report = pandas.DataFrame(columns=['text'])\n",
    "frag_path = pathlib.Path.cwd().parents[0] / 'data' / 'creator_match' \n",
    "for x in [x for x in frag_path.iterdir() if x.suffix == '.txt']:\n",
    "    with open(x) as fragment:\n",
    "        report.loc[len(report)] = [(fragment.read())]\n",
    "\n",
    "report = report.loc[~report.text.str.contains('wiki', na=False)]\n",
    "report['text'] = report['text'].str.split(' ').str[0]\n",
    "report = report.rename(columns={'text':'acmi_link'})\n",
    "report['acmi_id'] = report['acmi_link'].str.split('/').str[1].str.strip()\n",
    "\n",
    "acmi_roles = pandas.read_csv(pathlib.Path.cwd().parents[0] / 'data' / 'creator_roles' / 'creator_roles.csv', low_memory=False)\n",
    "acmi_roles = acmi_roles[['acmi_creator_id', 'acmi_creator_name', 'wikidata_type']]\n",
    "acmi_roles['acmi_creator_id'] = acmi_roles['acmi_creator_id'].astype(str)\n",
    "acmi_roles = acmi_roles.rename(columns={'acmi_creator_id':'acmi_id'})\n",
    "\n",
    "report = pandas.merge(report, acmi_roles, on='acmi_id', how='left')\n",
    "\n",
    "report = report.dropna().drop_duplicates(subset='acmi_link', keep='first')\n",
    "\n",
    "query = '''\n",
    "    select distinct ?wd ?acmi\n",
    "    where {?wd wdt:P7003 ?acmi} '''\n",
    "\n",
    "extant_acmi = sparql_query(query, 'https://query.wikidata.org/sparql').drop_duplicates()\n",
    "report = report.loc[~report.acmi_link.isin(list(extant_acmi.acmi))]\n",
    "\n",
    "\n",
    "# with open(pathlib.Path.home() / 'wikidata_login.json') as wd_cred:\n",
    "#     wd_cred = json.load(wd_cred)\n",
    "\n",
    "# config['USER_AGENT'] = 'acmi-notebooks (https://github.com/paulduchesne/acmi-notebooks)'\n",
    "# login_wikidata = wbi_login.Login(user=wd_cred['username'], password=wd_cred['password'], mediawiki_api_url='https://www.wikidata.org/w/api.php')\n",
    "# wbi = WikibaseIntegrator(login=login_wikidata)\n",
    "\n",
    "\n",
    "# for x in tqdm.tqdm(report.to_dict('records')):\n",
    "\n",
    "\n",
    "#     acmi_ref = References()\n",
    "#     ref = Reference()\n",
    "#     ref.add(datatypes.URL(prop_nr='P854', value=f\"https://www.acmi.net.au/{str(x['acmi_link'])}\"))\n",
    "#     acmi_ref.add(ref)\n",
    "\n",
    "#     new_creator = wbi.item.new()\n",
    "#     new_creator.labels.set('en', x['acmi_creator_name'])\n",
    "\n",
    "#     claim = datatypes.Item(prop_nr='P31', value=str(x['wikidata_type']), references=acmi_ref)    \n",
    "#     new_creator.claims.add(claim, action_if_exists=ActionIfExists.APPEND_OR_REPLACE)\n",
    "\n",
    "#     claim = datatypes.ExternalID(prop_nr='P7003', value=str(x['acmi_link']), references=acmi_ref)    \n",
    "#     new_creator.claims.add(claim, action_if_exists=ActionIfExists.APPEND_OR_REPLACE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # this is the command which actually makes the write to wikidata.\n",
    "#     r = new_creator.write()\n",
    "\n",
    "#    # print(new_creator)\n",
    "#    # print(r)\n",
    "\n",
    "\n",
    "print(len(report))\n",
    "report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>acmi</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>acmi_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>creators/83370 http://www.wikidata.org/entity/...</td>\n",
       "      <td>creators/83370</td>\n",
       "      <td>Q279413</td>\n",
       "      <td>https://www.acmi.net.au/creators/83370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>creators/78769 http://www.wikidata.org/entity/...</td>\n",
       "      <td>creators/78769</td>\n",
       "      <td>Q152239</td>\n",
       "      <td>https://www.acmi.net.au/creators/78769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>creators/73620 http://www.wikidata.org/entity/...</td>\n",
       "      <td>creators/73620</td>\n",
       "      <td>Q189022</td>\n",
       "      <td>https://www.acmi.net.au/creators/73620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>creators/82457 http://www.wikidata.org/entity/...</td>\n",
       "      <td>creators/82457</td>\n",
       "      <td>Q3566046</td>\n",
       "      <td>https://www.acmi.net.au/creators/82457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>creators/82730 http://www.wikidata.org/entity/...</td>\n",
       "      <td>creators/82730</td>\n",
       "      <td>Q24288349</td>\n",
       "      <td>https://www.acmi.net.au/creators/82730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text            acmi   \n",
       "72  creators/83370 http://www.wikidata.org/entity/...  creators/83370  \\\n",
       "76  creators/78769 http://www.wikidata.org/entity/...  creators/78769   \n",
       "78  creators/73620 http://www.wikidata.org/entity/...  creators/73620   \n",
       "97  creators/82457 http://www.wikidata.org/entity/...  creators/82457   \n",
       "98  creators/82730 http://www.wikidata.org/entity/...  creators/82730   \n",
       "\n",
       "     wikidata                               acmi_link  \n",
       "72    Q279413  https://www.acmi.net.au/creators/83370  \n",
       "76    Q152239  https://www.acmi.net.au/creators/78769  \n",
       "78    Q189022  https://www.acmi.net.au/creators/73620  \n",
       "97   Q3566046  https://www.acmi.net.au/creators/82457  \n",
       "98  Q24288349  https://www.acmi.net.au/creators/82730  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_candidates = pandas.DataFrame(columns=['text'])\n",
    "frag_path = pathlib.Path.cwd().parents[0] / 'data' / 'creator_match' \n",
    "for x in [x for x in frag_path.iterdir() if x.suffix == '.txt']:\n",
    "    with open(x) as fragment:\n",
    "        match_candidates.loc[len(match_candidates)] = [(fragment.read())]\n",
    "\n",
    "match_candidates = match_candidates.loc[match_candidates.text.str.contains('wiki', na=False)]\n",
    "match_candidates['acmi'] = match_candidates['text'].str.split(' ').str[0]\n",
    "match_candidates['wikidata'] = match_candidates['text'].str.split(' ').str[1]\n",
    "match_candidates['wikidata'] = match_candidates['wikidata'].str.split('/').str[-1]\n",
    "match_candidates['acmi_link'] = 'https://www.acmi.net.au/'+match_candidates['acmi']\n",
    "\n",
    "query = '''\n",
    "    select distinct ?wd ?acmi\n",
    "    where {?wd wdt:P7003 ?acmi} '''\n",
    "\n",
    "extant_acmi = sparql_query(query, 'https://query.wikidata.org/sparql').drop_duplicates()\n",
    "match_candidates = match_candidates.loc[~match_candidates.acmi.isin(list(extant_acmi.acmi))]\n",
    "\n",
    "match_candidates.to_csv(pathlib.Path.home() / 'Desktop' / 'acmi_manual.csv', index=False)\n",
    "print(len(match_candidates))\n",
    "match_candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
