{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Python dependencies\n",
        "!pip install edtf Wikidata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJRlxi6wBAMZ",
        "outputId": "e1e410e6-4832-4839-92cc-5e5d3b0914a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting edtf\n",
            "  Downloading edtf-4.0.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting Wikidata\n",
            "  Downloading Wikidata-0.7.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from edtf) (2.8.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from edtf) (3.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from edtf) (1.16.0)\n",
            "Installing collected packages: Wikidata, edtf\n",
            "Successfully installed Wikidata-0.7.0 edtf-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tuX79fDD_kXD"
      },
      "outputs": [],
      "source": [
        "# ACMI Wikidata importer for importing entity data to ACMI Creators\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "import requests\n",
        "from edtf import parse_edtf, struct_time_to_date\n",
        "from edtf.parser.edtf_exceptions import EDTFParseException\n",
        "from wikidata.client import Client as WikidataClient\n",
        "\n",
        "from IPython.display import display, HTML, Image\n",
        "\n",
        "\n",
        "class UnknownClaimID(Exception):\n",
        "    \"\"\"\n",
        "    This exception is raised when the claim ID for an external ID name is unknown.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class Wikidata:\n",
        "    \"\"\"\n",
        "    Imports Wikidata information for Works and Creators.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.wikidata_client = WikidataClient()\n",
        "        self.entity = None\n",
        "\n",
        "    def sparql_query(self, query):\n",
        "        \"\"\"\n",
        "        Send a sparql request to Wikidata.\n",
        "        \"\"\"\n",
        "        query_results = None\n",
        "        response = requests.get(\n",
        "            'https://query.wikidata.org/sparql',\n",
        "            params={\n",
        "                'format': 'json',\n",
        "                'query': query,\n",
        "            },\n",
        "            timeout=120,\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        try:\n",
        "            query_results = response.json()['results']['bindings']\n",
        "        except KeyError:\n",
        "            pass\n",
        "        return query_results\n",
        "\n",
        "    def search(self, query):\n",
        "        \"\"\"\n",
        "        Search Wikidata for any records it has for a query string.\n",
        "        \"\"\"\n",
        "        search_results = None\n",
        "        response = requests.get(\n",
        "            'https://www.wikidata.org/w/api.php',\n",
        "            params={\n",
        "                'action': 'wbsearchentities',\n",
        "                'format': 'json',\n",
        "                'language': 'en',\n",
        "                'search': query,\n",
        "            },\n",
        "            timeout=60,\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        try:\n",
        "            search_results = response.json()['search']\n",
        "        except KeyError:\n",
        "            pass\n",
        "        return search_results\n",
        "\n",
        "    def get_entity(self, wikidata_id):\n",
        "        \"\"\"\n",
        "        Get the entity from Wikidata by ID.\n",
        "        \"\"\"\n",
        "        self.entity = self.wikidata_client.get(wikidata_id, load=True)\n",
        "        return self.entity\n",
        "\n",
        "    def get_entity_by_tmdb_id(self, source_name, tmdb_id):\n",
        "        \"\"\"\n",
        "        Get the entity from Wikidata by its TMDB ID.\n",
        "        \"\"\"\n",
        "        claim_id = None\n",
        "        if source_name.lower() == 'tmdb-person':\n",
        "            claim_id = 'P4985'\n",
        "        elif source_name.lower() == 'tmdb-movie':\n",
        "            claim_id = 'P4947'\n",
        "        elif source_name.lower() == 'tmdb-tv':\n",
        "            claim_id = 'P4983'\n",
        "        else:\n",
        "            raise UnknownClaimID(f'Sorry, a TMDB claim ID for {source_name} isn\\'t implemented yet.')\n",
        "        query = f'PREFIX wdt: <http://www.wikidata.org/prop/direct/>\\nSELECT * {{ ?item wdt:{claim_id} \"{tmdb_id}\" }}'\n",
        "        response = self.sparql_query(query)\n",
        "        wikidata_id = response[0]['item']['value'].split('/')[-1]\n",
        "        return self.get_entity(wikidata_id)\n",
        "\n",
        "    def get_wikipedia_extract(self, wikidata_id):\n",
        "        \"\"\"\n",
        "        Get the Wikipedia extract for this Wikidata ID.\n",
        "        Returns the extract and Wikipedia URL.\n",
        "        \"\"\"\n",
        "        wikipedia_extract = None\n",
        "        wikipedia_url = None\n",
        "        if not self.entity:\n",
        "            self.get_entity(wikidata_id)\n",
        "        try:\n",
        "            response = requests.get(\n",
        "                'https://en.wikipedia.org/w/api.php',\n",
        "                params={\n",
        "                    'action': 'query',\n",
        "                    'format': 'json',\n",
        "                    'titles': self.entity.data['sitelinks']['enwiki']['title'],\n",
        "                    'prop': 'info|extracts',\n",
        "                    'exintro': True,\n",
        "                    'explaintext': True,\n",
        "                    'inprop': 'url',\n",
        "                },\n",
        "                timeout=60,\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            wikipedia_page = next(\n",
        "                iter(response.json()['query']['pages'].values()),\n",
        "            )\n",
        "            wikipedia_extract = wikipedia_page['extract']\n",
        "            wikipedia_url = wikipedia_page['canonicalurl']\n",
        "        except KeyError:\n",
        "            pass\n",
        "        return wikipedia_extract, wikipedia_url\n",
        "\n",
        "    def get_data(self, wikidata_id, data_name):\n",
        "        \"\"\"\n",
        "        Get an external ID from the Wikidata entity.\n",
        "        \"\"\"\n",
        "        data = None\n",
        "        if not self.entity:\n",
        "            self.get_entity(wikidata_id)\n",
        "\n",
        "        if data_name == 'imdb_id':\n",
        "            claim_id = 'P345'\n",
        "        elif data_name == 'tmdb_person':\n",
        "            claim_id = 'P4985'\n",
        "        elif data_name == 'tmdb_movie':\n",
        "            claim_id = 'P4947'\n",
        "        elif data_name == 'tmdb_tv':\n",
        "            claim_id = 'P4983'\n",
        "        elif data_name == 'viaf_id':\n",
        "            claim_id = 'P214'\n",
        "        elif data_name == 'loc_auth_id':\n",
        "            claim_id = 'P244'\n",
        "        elif data_name == 'worldcat_id':\n",
        "            claim_id = 'P7859'\n",
        "        elif data_name == 'date_of_birth':\n",
        "            claim_id = 'P569'\n",
        "        elif data_name == 'date_of_death':\n",
        "            claim_id = 'P570'\n",
        "        elif data_name == 'country_of_citizenship':\n",
        "            claim_id = 'P27'\n",
        "        elif data_name == 'also_known_as':\n",
        "            claim_id = 'P1477'\n",
        "        else:\n",
        "            raise UnknownClaimID(f'Sorry, a claim ID for {data_name} isn\\'t implemented yet.')\n",
        "\n",
        "        try:\n",
        "            data = self.entity.data['claims'][claim_id][0]['mainsnak']['datavalue']['value']\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "        return data\n",
        "\n",
        "    def get_image_url(self, wikidata_id):\n",
        "        \"\"\"\n",
        "        Get an Image url from the Wikidata entity.\n",
        "        \"\"\"\n",
        "        image_url = None\n",
        "        if not self.entity:\n",
        "            self.get_entity(wikidata_id)\n",
        "        try:\n",
        "            image_url = self.entity[self.wikidata_client.get('P18')].image_url\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "        return image_url\n",
        "\n",
        "    def get_image_license(self, wikidata_id):\n",
        "        \"\"\"\n",
        "        Retrieve the license information from Wikimedia commons.\n",
        "        Returns an HTML formatted string.\n",
        "        \"\"\"\n",
        "        license_html = None\n",
        "        if not self.entity:\n",
        "            self.get_entity(wikidata_id)\n",
        "        filename = None\n",
        "        try:\n",
        "            filename = self.entity[self.wikidata_client.get('P18')].attributes['title']\n",
        "            response = requests.get(\n",
        "                'https://commons.wikimedia.org/w/api.php',\n",
        "                params={\n",
        "                    'action': 'query',\n",
        "                    'format': 'json',\n",
        "                    'iiprop': 'extmetadata',\n",
        "                    'prop': 'imageinfo',\n",
        "                    'titles': filename,\n",
        "                },\n",
        "                timeout=60,\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            search_results = response.json()['query']['pages']\n",
        "            page_key = list(search_results.keys())[0]\n",
        "            license_information = search_results[page_key]['imageinfo'][0]['extmetadata']\n",
        "            artist = license_information['Artist']['value']\n",
        "            wikimedia_page_url = f'https://commons.wikimedia.org/wiki/{filename}'\n",
        "            license_name = license_information['LicenseShortName']['value']\n",
        "            if license_name == 'Public domain':\n",
        "                license_url = 'https://wikipedia.org/wiki/Wikipedia:Public_domain'\n",
        "            else:\n",
        "                license_url = license_information['LicenseUrl']['value']\n",
        "            license_html = f'<p>{artist}/<a href=\"{wikimedia_page_url}\">Wikimedia</a> '\\\n",
        "                           f'(<a href=\"{license_url}\">{license_name}</a>)</p>'\n",
        "        except KeyError:\n",
        "            pass\n",
        "        return license_html\n",
        "\n",
        "    def print_all(self, wikidata_id):\n",
        "        \"\"\"\n",
        "        Print all Wikidata data for an Entity ID.\n",
        "        \"\"\"\n",
        "        entity = self.get_entity(wikidata_id)\n",
        "\n",
        "        if entity:\n",
        "            try:\n",
        "                date_of_birth = self.wikidata_date_to_iso8601_date(\n",
        "                    self.get_data(entity.id, 'date_of_birth')['time']\n",
        "                )\n",
        "                print(f'Date of birth: {date_of_birth}')\n",
        "            except TypeError:\n",
        "                pass\n",
        "            try:\n",
        "                date_of_death = self.wikidata_date_to_iso8601_date(\n",
        "                    self.get_data(entity.id, 'date_of_death')['time']\n",
        "                )\n",
        "                print(f'Date of death: {date_of_death}')\n",
        "            except TypeError:\n",
        "                pass\n",
        "            country_entity_data = self.get_data(entity.id, 'country_of_citizenship')\n",
        "            if country_entity_data:\n",
        "                country_entity = self.wikidata_client.get(country_entity_data['id'])\n",
        "                if country_entity and country_entity.label:\n",
        "                    print(f'Country of citizenship: {country_entity.label}')\n",
        "            wikipedia_extract, wikipedia_page = self.get_wikipedia_extract(entity.id)\n",
        "            if wikipedia_extract:\n",
        "                print(f'Wikipedia extract: {wikipedia_extract}')\n",
        "            if wikipedia_page:\n",
        "                print(f'Wikipedia URL: {wikipedia_page}')\n",
        "\n",
        "            # Django removes \"%\" symbols when saving to the database\n",
        "            image_url = self.get_image_url(entity.id).replace('%', '')\n",
        "            wikidata_image = None\n",
        "            if image_url:\n",
        "                print(f'Image URL: {image_url}')\n",
        "                display(Image(url=image_url))\n",
        "\n",
        "            credit_line = self.get_image_license(entity.id)\n",
        "            if credit_line:\n",
        "                display(HTML(credit_line))\n",
        "\n",
        "            also_known_as = self.get_data(entity.id, 'also_known_as')\n",
        "            if also_known_as:\n",
        "                print(f\"AKA: {also_known_as['text']}\")\n",
        "\n",
        "    def wikidata_date_to_iso8601_date(self, wikidata_date):\n",
        "        \"\"\"\n",
        "        Convert Wikidata date with signed year to iso8601 date format.\n",
        "        e.g. +1953-07-01T00:00:00Z to 1953-07-01\n",
        "        \"\"\"\n",
        "        iso8601_date = None\n",
        "        # Remove signed year\n",
        "        if wikidata_date and wikidata_date.startswith('+'):\n",
        "            wikidata_date = wikidata_date[1:]\n",
        "\n",
        "        try:\n",
        "            edtf_format = parse_edtf(wikidata_date)\n",
        "            iso8601_date = str(struct_time_to_date(edtf_format.lower_strict()))\n",
        "        except (EDTFParseException, ValueError):\n",
        "            pass\n",
        "\n",
        "        return iso8601_date\n",
        "\n",
        "    def get_wikidata_entities_with_acmi_ids(self):\n",
        "        \"\"\"\n",
        "        Get all Wikidata entities that have ACMI IDs (P7003 claims).\n",
        "\n",
        "        Returns a dictionary of works and creators tuples.\n",
        "        e.g. 'works': [(Wikidata ID, XOS Work ID)]\n",
        "        \"\"\"\n",
        "        wikidata_entities = {}\n",
        "        query = 'select ?acmi_id ?wikidata_id where { ?wikidata_id wdt:P7003 ?acmi_id }'\n",
        "        responses = self.sparql_query(query)\n",
        "        for item in responses:\n",
        "            wikidata_id = item['wikidata_id']['value'].split('/')[-1]\n",
        "            acmi_id_parts = item['acmi_id']['value'].split('/')\n",
        "            if not wikidata_entities.get(acmi_id_parts[0]):\n",
        "                wikidata_entities[acmi_id_parts[0]] = set()\n",
        "            wikidata_entities[acmi_id_parts[0]].add((wikidata_id, int(acmi_id_parts[-1])))\n",
        "        return wikidata_entities\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage getting all information available\n",
        "wikidata = Wikidata()\n",
        "wikidata.print_all('Q438911')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "Pfe0d7R5DiQy",
        "outputId": "8ccfcc3c-259f-4565-aef8-5151681dfdb0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date of birth: 1950-12-18\n",
            "Country of citizenship: Australia\n",
            "Wikipedia extract: Gillian May Armstrong (born 18 December 1950) is an Australian feature film and documentary director, best known for My Brilliant Career, Little Women, The Last Days of Chez Nous, and Mrs. Soffel. She is a Member of the Order of Australia.She has won multiple awards including an AFI Best Director Award, and has been nominated for numerous other awards including a Palme D'Or  and two Golden Bear Awards. She has received multiple Honorary Doctorates including an Honorary Doctor of Letter Degree from University of Sydney, and an Honorary Doctorate from Swinburne University of Technology.\n",
            "Wikipedia URL: https://en.wikipedia.org/wiki/Gillian_Armstrong\n",
            "Image URL: https://upload.wikimedia.org/wikipedia/commons/1/11/Gillian_Armstrong.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/11/Gillian_Armstrong.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p><bdi><a href=\"https://www.wikidata.org/wiki/Q37885816\" class=\"extiw\" title=\"d:Q37885816\"><span title=\"Australian photographer\">Eva Rinaldi</span></a>\n",
              "</bdi>/<a href=\"https://commons.wikimedia.org/wiki/File:Gillian Armstrong.jpg\">Wikimedia</a> (<a href=\"https://creativecommons.org/licenses/by-sa/2.0\">CC BY-SA 2.0</a>)</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example searching for a person in Wikidata\n",
        "wikidata = Wikidata()\n",
        "wikidata.search('Tilda Swinton')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojssP-l6GtHy",
        "outputId": "f63cad76-a411-4b2c-ec5f-ebfe021fbf44"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'Q200534',\n",
              "  'title': 'Q200534',\n",
              "  'pageid': 197299,\n",
              "  'display': {'label': {'value': 'Tilda Swinton', 'language': 'en'},\n",
              "   'description': {'value': 'Scottish-British actress', 'language': 'en'}},\n",
              "  'repository': 'wikidata',\n",
              "  'url': '//www.wikidata.org/wiki/Q200534',\n",
              "  'concepturi': 'http://www.wikidata.org/entity/Q200534',\n",
              "  'label': 'Tilda Swinton',\n",
              "  'description': 'Scottish-British actress',\n",
              "  'match': {'type': 'label', 'language': 'en', 'text': 'Tilda Swinton'}},\n",
              " {'id': 'Q113726485',\n",
              "  'title': 'Q113726485',\n",
              "  'pageid': 108483900,\n",
              "  'display': {'label': {'value': 'Tilda Swinton. The Love Factory',\n",
              "    'language': 'en'},\n",
              "   'description': {'value': '2002 short film directed by Luca Guadagnino',\n",
              "    'language': 'en'}},\n",
              "  'repository': 'wikidata',\n",
              "  'url': '//www.wikidata.org/wiki/Q113726485',\n",
              "  'concepturi': 'http://www.wikidata.org/entity/Q113726485',\n",
              "  'label': 'Tilda Swinton. The Love Factory',\n",
              "  'description': '2002 short film directed by Luca Guadagnino',\n",
              "  'match': {'type': 'label',\n",
              "   'language': 'en',\n",
              "   'text': 'Tilda Swinton. The Love Factory'}},\n",
              " {'id': 'Q110894035',\n",
              "  'title': 'Q110894035',\n",
              "  'pageid': 105913733,\n",
              "  'display': {'label': {'value': 'Tilda Swinton: The Maybe', 'language': 'en'},\n",
              "   'description': {'value': '2013 exhibition at Museum of Modern Art',\n",
              "    'language': 'en'}},\n",
              "  'repository': 'wikidata',\n",
              "  'url': '//www.wikidata.org/wiki/Q110894035',\n",
              "  'concepturi': 'http://www.wikidata.org/entity/Q110894035',\n",
              "  'label': 'Tilda Swinton: The Maybe',\n",
              "  'description': '2013 exhibition at Museum of Modern Art',\n",
              "  'match': {'type': 'label',\n",
              "   'language': 'en',\n",
              "   'text': 'Tilda Swinton: The Maybe'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example getting a Wikidata entity by a TMDB ID\n",
        "wikidata = Wikidata()\n",
        "wikidata.get_entity_by_tmdb_id('TMDB-Person', '1620')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85od_M5xHaeO",
        "outputId": "4772d7ab-be50-47fd-96e6-560338a4f5fd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wikidata.entity.Entity Q214289 'Michelle Yeoh'>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example printing all of the ACMI IDs in Wikidata\n",
        "wikidata = Wikidata()\n",
        "acmi_links = wikidata.get_wikidata_entities_with_acmi_ids()\n",
        "print(f'There are {len(acmi_links[\"works\"])} ACMI Works, and {len(acmi_links[\"creators\"])} ACMI Creators in Wikidata')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCcJEPTmF6_H",
        "outputId": "d439c849-b0c6-4749-b024-7729b34886e8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 7153 ACMI Works, and 17202 ACMI Creators in Wikidata\n"
          ]
        }
      ]
    }
  ]
}